test02.py의 기존 구조를 참고해서, 아래 조건에 따라 화자 분리(diarization) 단계를 추가하는 코드를 작성해 주세요.

- 음성파일을 pyannote.audio로 화자 분리(diarization)하여 화자별 구간(시작·끝, 화자ID)를 추출
- 각 화자 세그먼트를 Whisper API로 인식하여 텍스트로 변환
- 각 화자의 텍스트를 구분해서 출력 및 파일 저장(예: 화자별 구분된 마크다운, txt, json 등)
- pyannote.audio 모델 사용 시 필요한 토큰 요청 및 .env의 pyannote 토큰 참고
- 주요 과정(화자 분리 → STT 변환 → 출력 및 저장)이 함수로 분리되어 있으면 좋음
- 코드는 실행 및 디버깅이 쉽게 작성할 것
- pyannote, openai 등 필요한 모든 모듈 임포트 포함

===

Hugging Face API 토큰을 .env에서 읽어 인증 처리하는 Python 코드를 작성해 주세요.

- pyannote.audio를 활용해 입력 음성 파일에 대해 화자 분리 수행
- 화자 분리된 각 음성 세그먼트에 대해 Whisper API로 STT 실행
- 각 화자별 발언 내용을 마크다운 형식으로 구분하여 출력
- 결과를 마크다운(.md) 파일로 저장하는 기능 포함
- 필요한 라이브러리 임포트, 인증, 에러 처리 모두 포함
- 코드 전체가 실행 가능하도록 간결하고 명확하게 작성


===

기존 test03.py 파일을 수정하는 Python 코드를 생성해 주세요.

1. 스크립트 실행 시 별도의 인자 없이 `python test03.py`만 입력하면 동작하도록 변경
2. 코드 상단에 `audio_file_path`와 같은 변수를 추가해 음성 파일 경로를 직접 설정할 수 있게 할 것
3. 기존 인자 처리 부분 또는 하드코딩 되어 있던 파일 경로 부분을 이 변수로 대체
4. 나머지 코드는 기존 기능을 유지하며, 간결하고 이해하기 쉬운 형태로 수정

전체 코드가 실행 가능한 상태여야 합니다.


