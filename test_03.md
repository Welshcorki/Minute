test02.py의 기존 구조를 참고해서, 아래 조건에 따라 화자 분리(diarization) 단계를 추가하는 코드를 작성해 주세요.

- 음성파일을 pyannote.audio로 화자 분리(diarization)하여 화자별 구간(시작·끝, 화자ID)를 추출
- 각 화자 세그먼트를 Whisper API로 인식하여 텍스트로 변환
- 각 화자의 텍스트를 구분해서 출력 및 파일 저장(예: 화자별 구분된 마크다운, txt, json 등)
- pyannote.audio 모델 사용 시 필요한 토큰 요청 및 .env의 pyannote 토큰 참고
- 주요 과정(화자 분리 → STT 변환 → 출력 및 저장)이 함수로 분리되어 있으면 좋음
- 코드는 실행 및 디버깅이 쉽게 작성할 것
- pyannote, openai 등 필요한 모든 모듈 임포트 포함

===

Hugging Face API 토큰을 .env에서 읽어 인증 처리하는 Python 코드를 작성해 주세요.

- pyannote.audio를 활용해 입력 음성 파일에 대해 화자 분리 수행
- 화자 분리된 각 음성 세그먼트에 대해 Whisper API로 STT 실행
- 각 화자별 발언 내용을 마크다운 형식으로 구분하여 출력
- 결과를 마크다운(.md) 파일로 저장하는 기능 포함
- 필요한 라이브러리 임포트, 인증, 에러 처리 모두 포함
- 코드 전체가 실행 가능하도록 간결하고 명확하게 작성
